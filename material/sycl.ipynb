{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa1751",
   "metadata": {},
   "source": [
    "# SYCL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7837bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Level 0: Hello World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a20d50",
   "metadata": {},
   "source": [
    "We start with a serial CPU code printing a range of numbers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e03ebb6",
   "metadata": {},
   "source": [
    "```cpp\n",
    "for (size_t i0 = 0; i0 < nx; ++i0) {\n",
    "    printf(\"%ld\\n\", i0);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970a674",
   "metadata": {},
   "source": [
    "The full example is available in [print-numbers-base.cpp](../src/print-numbers/print-numbers-base.cpp), and can be compiled and executed using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1926a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -O3 -march=native -std=c++17 -o ../build/print-numbers/print-numbers-base ../src/print-numbers/print-numbers-base.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "!../build/print-numbers/print-numbers-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a3f48",
   "metadata": {},
   "source": [
    "SYCL also provides an abstraction for parallel loops.\n",
    "Using it requires a *handler*, which in turn requires a work *queue*.\n",
    "\n",
    "The latter can be initialized with the `in_order` property that ensures that kernels and other operations are executed in order.\n",
    "\n",
    "```cpp\n",
    "sycl::queue q(sycl::property::queue::in_order{});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35d5b2",
   "metadata": {},
   "source": [
    "Work can then be submitted to the queue which provides a handler\n",
    "\n",
    "```cpp\n",
    "q.submit([&](sycl::handler &h) {\n",
    "    h.parallel_for(nx, [=](auto i0) {\n",
    "        // this won't work yet\n",
    "        printf(\"%ld\\n\", i0);\n",
    "    });\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fdcb20",
   "metadata": {},
   "source": [
    "`printf` is, in contrast to most other approaches, _not_ supported in SYCL.\n",
    "One working alternative is using sycl streams.\n",
    "Below is the complete snippet excluding the setup of the queue `q`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e923bd5",
   "metadata": {},
   "source": [
    "```cpp\n",
    "q.submit([&](sycl::handler &h) {\n",
    "    sycl::stream str(8192, 1024, h); // use sycl stream instead of printf\n",
    "    h.parallel_for(nx, [=](auto i0) {\n",
    "        // printf(\"%ld\\n\", i0);\n",
    "        str << (size_t)i0 << sycl::endl; // use sycl endl\n",
    "    });\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7975b",
   "metadata": {},
   "source": [
    "You can tune the workgroup size by specifying global and local sizes (the total number of threads and the number of threads per workgroup).\n",
    "Note that these must be evenly divisible, and any extra threads may need to be masked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc14e0",
   "metadata": {},
   "source": [
    "```cpp\n",
    "auto local_size = 256;\n",
    "auto global_size = ceilingDivide(nx, local_size) * local_size;\n",
    "q.submit([&](sycl::handler &h) {\n",
    "    sycl::stream str(8192, 1024, h); // use sycl stream instead of printf\n",
    "    h.parallel_for( sycl::nd_range<1>{ global_size, local_size }, [=](auto item) {\n",
    "        auto i0 = item.get_global_id(0);\n",
    "        if (i0 < nx) {\n",
    "            str << (size_t)i0 << sycl::endl; // use sycl endl\n",
    "        }\n",
    "    });\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f0610",
   "metadata": {},
   "source": [
    "In all cases, explicit synchronization with the GPU is performed by calling:\n",
    "\n",
    "```cpp\n",
    "q.wait();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f36e1",
   "metadata": {},
   "source": [
    "The full example is available in [print-numbers-sycl.cpp](../src/print-numbers/print-numbers-sycl.cpp), and can be compiled and executed using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fbe3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!icpx -O3 -march=native -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_86 -o ../build/print-numbers/print-numbers-sycl ../src/print-numbers/print-numbers-sycl.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!../build/print-numbers/print-numbers-sycl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af6a43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Level 1: Adding Managed Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b0a6e",
   "metadata": {},
   "source": [
    "Our next application is increasing all elements of an array by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43501576",
   "metadata": {},
   "source": [
    "[increase-base.cpp](../src/increase/increase-base.cpp) shows a serial CPU-only implementation.\n",
    "Its key part and our entry point is the increase function.\n",
    "\n",
    "```cpp\n",
    "void increase(double* data, size_t nx) {\n",
    "    for (size_t i0 = 0; i0 < nx; ++i0) {\n",
    "        data[i0] += 1;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e98d6",
   "metadata": {},
   "source": [
    "Data allocation and deallocation is done explicitly in SYCL.\n",
    "For the case of managed memory this works as follows (again assuming an initialized queue `q`).\n",
    "\n",
    "```cpp\n",
    "double *data;                  // unified allocation\n",
    "data = sycl::malloc_shared<double>(nx, q);\n",
    "\n",
    "/* ... */\n",
    "\n",
    "sycl::free(data, q);           // unified de-allocation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd25f77",
   "metadata": {},
   "source": [
    "Pre-fetching *to the device* can be performed as an additional optimization.\n",
    "\n",
    "```cpp\n",
    "q.prefetch(data, nx * sizeof(double));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d795b05",
   "metadata": {},
   "source": [
    "The allocated (managed) arrays can be used directly in kernels.\n",
    "\n",
    "```cpp\n",
    "q.submit([&](sycl::handler &h) {\n",
    "    h.parallel_for(nx, [=](auto i0) {\n",
    "        data[i0] += 1;\n",
    "    });\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a362f",
   "metadata": {},
   "source": [
    "The complete example code is available in [increase-sycl-mm.cpp](../src/increase/increase-sycl-mm.cpp), and can be built and executed using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!icpx -O3 -march=native -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_86 -o ../build/increase/increase-sycl-mm ../src/increase/increase-sycl-mm.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd5fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!../build/increase/increase-sycl-mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff69508",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Level 2: Switching to Explicit Memory Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75930b",
   "metadata": {},
   "source": [
    "Switching from managed memory to explicit memory management requires the following changes and additions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23437455",
   "metadata": {},
   "source": [
    "**1.** Separate device and host allocations\n",
    "\n",
    "```cpp\n",
    "double *data;                  // host allocation\n",
    "data = sycl::malloc_host<double>(nx, q);\n",
    "\n",
    "double *d_data;                // device allocation    \n",
    "d_data = sycl::malloc_device<double>(nx, q);\n",
    "\n",
    "/* ... */\n",
    "\n",
    "sycl::free(d_data, q);         // device de-allocation\n",
    "\n",
    "sycl::free(data, q);           // host de-allocation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007fa5c",
   "metadata": {},
   "source": [
    "**2.** Explicit copies between host and device\n",
    "\n",
    "```cpp\n",
    "q.memcpy(d_data, data, sizeof(double) * nx);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c124c",
   "metadata": {},
   "source": [
    "The complete example code is available in [increase-sycl-expl.cpp](../src/increase/increase-sycl-expl.cpp).\n",
    "Build and execute it using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1992b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!icpx -O3 -march=native -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_86 -o ../build/increase/increase-sycl-expl ../src/increase/increase-sycl-expl.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "!../build/increase/increase-sycl-expl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ee40c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bonus Level: Using SYCL Buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d64af",
   "metadata": {},
   "source": [
    "In addition to the two variants of managing memory discussed so far, SYCL also offers a buffer and accessor system.\n",
    "This, among other things, allows for setting up dependency graphs and automatic host-device data transfers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e7ed1",
   "metadata": {},
   "source": [
    "```cpp\n",
    "double *data;                  // host allocation\n",
    "data = new double[nx];\n",
    "\n",
    "{\n",
    "    // device buffer allocation\n",
    "    sycl::buffer b_data(data, sycl::range(nx));\n",
    "} // implicit device to host -H copy of destroyed buffers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4854c9e9",
   "metadata": {},
   "source": [
    "When using buffers, you must create additional accessors to access data.\n",
    "\n",
    "```cpp\n",
    "q.submit([&](sycl::handler &h) {\n",
    "    auto data = b_data.get_access(h, sycl::read_write);\n",
    "    h.parallel_for(nx, [=](auto i0) {\n",
    "        data[i0] += 1;\n",
    "    });\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d3618f",
   "metadata": {},
   "source": [
    "The complete example code is available in [increase-sycl-buffer.cpp](../src/increase/increase-sycl-buffer.cpp), and is built and executed using the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!icpx -O3 -march=native -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_86 -o ../build/increase/increase-sycl-expl ../src/increase/increase-sycl-expl.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f14989",
   "metadata": {},
   "outputs": [],
   "source": [
    "!../build/increase/increase-sycl-expl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
